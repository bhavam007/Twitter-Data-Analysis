{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "architectural-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import operator\n",
    "import itertools \n",
    "from configu import credentials\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tender-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = credentials[\"api_key\"]\n",
    "sec_key = credentials[\"sec_key\"]\n",
    "access_token = credentials[\"access_token\"]\n",
    "access_token_secret = credentials[\"access_token_secret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "copyrighted-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.AppAuthHandler(api_key, sec_key)\n",
    "auth.secure = True\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "commercial-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_ht = []\n",
    "for t in tw.Cursor(api.search, q=\"#Covid19IndiaHelp\", lang=\"en\", tweet_mode='extended').items(2000):\n",
    "    main_ht.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "answering-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file = open(\"main_hashtag.txt\", \"wb\")\n",
    "pickle.dump(main_ht, open_file)\n",
    "open_file.close()\n",
    "\n",
    "open_file = open(\"main_hashtag.txt\", \"rb\")\n",
    "main_ht = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_ht = []\n",
    "top10_ht = []\n",
    "\n",
    "for tweet in main_ht:\n",
    "    tw_ht = []\n",
    "    for ht in tweet.entities['hashtags']:\n",
    "        if (ht['text'] != \"Covid19IndiaHelp\"):\n",
    "            tw_ht.append(ht['text'])\n",
    "    other_ht.extend(list(set(tw_ht)))\n",
    "\n",
    "occurence_count = Counter(other_ht)\n",
    "for ht in occurence_count.most_common(10):\n",
    "    top10_ht.append(ht[0])\n",
    "    \n",
    "print(top10_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "white-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(ht):\n",
    "    tweets_for_ht = []\n",
    "    for t in tw.Cursor(api.search, q=ht, lang=\"en\", tweet_mode='extended').items(2000):\n",
    "        tweets_for_ht.append(t)\n",
    "    return tweets_for_ht\n",
    "\n",
    "dict for top 10 hashtags containing their tweets (2000 each)\n",
    "ht_dict = {}\n",
    "for ht in top10_ht:\n",
    "    ht_dict[ht] = get_tweets(ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "graduate-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_dict['Covid19IndiaHelp'] = main_ht\n",
    "open_file = open(\"sec2_all_tweets_dict.txt\", \"wb\")\n",
    "pickle.dump(ht_dict, open_file)\n",
    "open_file.close()\n",
    "\n",
    "open_file = open(\"sec2_all_tweets_dict.txt\", \"rb\")\n",
    "ht_dict = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "defensive-conference",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_tweets = []\n",
    "\n",
    "for tw_list in ht_dict.values():\n",
    "    all_tweets.extend(tw_list)\n",
    "\n",
    "most_occ = {}\n",
    "most_likes = {}\n",
    "most_rt = {}\n",
    "\n",
    "for tweet in all_tweets:\n",
    "    temp_ht = []\n",
    "    \n",
    "    for ht in tweet.entities['hashtags']:\n",
    "        if (ht['text'] != \"Covid19IndiaHelp\"):\n",
    "            temp_ht.append(ht['text'])\n",
    "            \n",
    "    for uniq_ht in (list(set(temp_ht))):\n",
    "        \n",
    "        #most number of occurrences\n",
    "        if(uniq_ht in most_occ):\n",
    "            most_occ[uniq_ht] += 1\n",
    "        else:\n",
    "            most_occ[uniq_ht] = 1\n",
    "    \n",
    "        #most number of likes\n",
    "        if(uniq_ht in most_likes):\n",
    "            most_likes[uniq_ht] += tweet.favorite_count\n",
    "        else:\n",
    "            most_likes[uniq_ht] = tweet.favorite_count\n",
    "            \n",
    "        #most number of retweets\n",
    "        if(uniq_ht in most_rt):\n",
    "            most_rt[uniq_ht] += tweet.retweet_count\n",
    "        else:\n",
    "            most_rt[uniq_ht] = tweet.retweet_count\n",
    "    \n",
    "\n",
    "most_occ = dict(sorted(most_occ.items(), key=operator.itemgetter(1),reverse=True))\n",
    "topmost_occ = dict(itertools.islice(most_occ.items(),10))\n",
    "\n",
    "most_likes = dict(sorted(most_likes.items(), key=operator.itemgetter(1),reverse=True))\n",
    "topmost_likes = dict(itertools.islice(most_likes.items(),10))\n",
    "\n",
    "most_rt = dict(sorted(most_rt.items(), key=operator.itemgetter(1),reverse=True))\n",
    "topmost_rt = dict(itertools.islice(most_rt.items(),10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "female-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "barlist1 = plt.bar(topmost_occ.keys(), topmost_occ.values())\n",
    "plt.xlabel('Hashtag')\n",
    "plt.ylabel('Number of occurrences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prescribed-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "barlist2 = plt.bar(topmost_likes.keys(), topmost_likes.values())\n",
    "plt.xlabel('Hashtag')\n",
    "plt.ylabel('Number of likes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sophisticated-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "barlist2 = plt.bar(topmost_rt.keys(), topmost_rt.values())\n",
    "plt.xlabel('Hashtag')\n",
    "plt.ylabel('Number of retweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_calc(hashtag):\n",
    "    no_of_t = 0\n",
    "    no_of_rt = 0\n",
    "    for tweet in all_tweets:\n",
    "        have_hash = False\n",
    "        for ht in tweet.entities['hashtags']:\n",
    "            if(hashtag in ht.values()):\n",
    "                have_hash = True\n",
    "                no_of_t += 1\n",
    "        try:\n",
    "            if(tweet.retweeted_status and have_hash):\n",
    "                no_of_rt += 1\n",
    "        except:\n",
    "            continue        \n",
    "    return (no_of_rt*100)/no_of_t\n",
    "\n",
    "def F_calc(hashtag):\n",
    "    \n",
    "    total_users = {}\n",
    "    tu_tweets = 0\n",
    "    for tweet in all_tweets:\n",
    "        for ht in tweet.entities['hashtags']:\n",
    "            if(hashtag in ht.values()):\n",
    "                if(tweet.user.id in total_users):\n",
    "                    total_users[tweet.user.id] += 1\n",
    "                else:\n",
    "                    total_users[tweet.user.id] = 1\n",
    "    \n",
    "    total_users = dict(sorted(total_users.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    \n",
    "    traffic_50 = 0\n",
    "    traffic_total = 0\n",
    "    count = 0\n",
    "    for i in total_users.values():\n",
    "        count += 1\n",
    "        traffic_total += i\n",
    "        if(count < 50):\n",
    "            traffic_50 += i\n",
    "    return (traffic_50*100)/traffic_total\n",
    "\n",
    "def U_calc(hashtag):\n",
    "    total_users = {}\n",
    "    total_tweets = 0\n",
    "    for tweet in all_tweets:\n",
    "        for ht in tweet.entities['hashtags']:\n",
    "            if(hashtag in ht.values()):\n",
    "                if(tweet.user.id in total_users):\n",
    "                    total_users[tweet.user.id] += 1\n",
    "                else:\n",
    "                    total_users[tweet.user.id] = 1\n",
    "                    \n",
    "    for i in total_users.values():\n",
    "        total_tweets += i\n",
    "    return total_tweets/len(total_users)\n",
    "    \n",
    "R_dict_occ = {}\n",
    "F_dict_occ = {}\n",
    "U_dict_occ = {}\n",
    "\n",
    "R_dict_likes = {}\n",
    "F_dict_likes = {}\n",
    "U_dict_likes = {}\n",
    "\n",
    "R_dict_rt = {}\n",
    "F_dict_rt = {}\n",
    "U_dict_rt = {}\n",
    "\n",
    "for hashtag in topmost_occ.keys():\n",
    "    R_dict_occ[hashtag] = R_calc(hashtag)\n",
    "    F_dict_occ[hashtag] = F_calc(hashtag)\n",
    "    U_dict_occ[hashtag] = U_calc(hashtag)\n",
    "    \n",
    "for hashtag in topmost_likes.keys():\n",
    "    R_dict_likes[hashtag] = R_calc(hashtag)\n",
    "    F_dict_likes[hashtag] = F_calc(hashtag)\n",
    "    U_dict_likes[hashtag] = U_calc(hashtag)\n",
    "    \n",
    "for hashtag in topmost_rt.keys():\n",
    "    R_dict_rt[hashtag] = R_calc(hashtag)\n",
    "    F_dict_rt[hashtag] = F_calc(hashtag)\n",
    "    U_dict_rt[hashtag] = U_calc(hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctm_occ = {}\n",
    "ctm_likes = {}\n",
    "ctm_rt = {}\n",
    "\n",
    "for i in range(10):\n",
    "    top_occ = list(topmost_occ.keys())\n",
    "    ht_occ = top_occ[i]\n",
    "    ctm_occ[ht_occ] = (R_dict_occ[ht_occ]/10) + F_dict_occ[ht_occ] + U_dict_occ[ht_occ]\n",
    "    \n",
    "    top_likes = list(topmost_likes.keys())\n",
    "    ht_likes = top_likes[i]\n",
    "    ctm_likes[ht_likes] = (R_dict_likes[ht_likes]/10) + F_dict_likes[ht_likes] + U_dict_likes[ht_likes]\n",
    "    \n",
    "    top_rt = list(topmost_rt.keys())\n",
    "    ht_rt = top_rt[i]\n",
    "    ctm_rt[ht_rt] = (R_dict_rt[ht_rt]/10) + F_dict_rt[ht_rt] + U_dict_rt[ht_rt]\n",
    "\n",
    "print(ctm_occ)\n",
    "print(ctm_likes)\n",
    "print(ctm_rt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
